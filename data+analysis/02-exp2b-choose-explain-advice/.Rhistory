logit(phi[i]) = b0 + b[1]*Age[i] + b[2]*OMElow[i] + b[3]*Loud[i] + b[4]*Noiseincoherent[i]
}
b0 ~ dnorm(0.0, 1.0/5.0^2)
for (j in 1:4) {
b[j] ~ dnorm(0.0, 1.0/4.0^2)
}
} "
data_jags <- as.list(as.data.frame(X))
data_jags$y <- dat$Correct # this will not work if there are missing values in dat (because they would be ignored by model.matrix). Always make sure that the data are accurately pre-processed for JAGS.
data_jags$n <- dat$Trials
str(data_jags) # make sure that all variables have the same number of observations (712).
params <- c("b0", "b")
mod <- jags.model(textConnection(mod_string), data=data_jags, n.chains=3)
update(mod, 1e3)
mod_sim <- coda.samples(model=mod,
variable.names=params,
n.iter=5e3)
mod_csim <- as.mcmc(do.call(rbind, mod_sim)) # combined chains
summary(mod_csim)
raftery.diag(mod_sim)
# posterior means from your MCMC object
m <- colMeans(do.call(rbind, mod_sim))  # names: "b0", "b[1]", "b[2]", "b[3]", "b[4]"
eta <- m["b0"] + 60*m["b[1]"] + 0*m["b[2]"] + 50*m["b[3]"] + 0*m["b[4]"]
p_hat <- 1/(1 + exp(-eta))
round(p_hat, 2)
eta <- m["b0"] +
m["b[1]"] * dat$Age +
m["b[2]"] * dat$OMElow +
m["b[3]"] * dat$Loud +
m["b[4]"] * dat$Noiseincoherent
phat <- 1 / (1 + exp(-eta))
obs_rate <- dat$Correct / dat$Trials
tab0.7 <- table(phat > 0.7, obs_rate > 0.7)
phat <- 1 / (1 + exp(-eta))
phat
eta
# Posterior means for each coefficient
m <- colMeans(do.call(rbind, mod_sim))
eta <- m["b0"] +
m["b[1]"] * dat$Age +
m["b[2]"] * dat$OMElow +
m["b[3]"] * dat$Loud +
m["b[4]"] * dat$Noiseincoherent
phat <- 1 / (1 + exp(-eta))
obs_rate <- dat$Correct / dat$Trials
tab0.7 <- table(phat > 0.7, obs_rate > 0.7)
m
# Posterior means for each coefficient
m <- model_csim
eta <- m["b0"] +
m["b[1]"] * dat$Age +
m["b[2]"] * dat$OMElow +
m["b[3]"] * dat$Loud +
m["b[4]"] * dat$Noiseincoherent
phat <- 1 / (1 + exp(-eta))
obs_rate <- dat$Correct / dat$Trials
tab0.7 <- table(phat > 0.7, obs_rate > 0.7)
# Posterior means for each coefficient
m <- mod_csim
eta <- m["b0"] +
m["b[1]"] * dat$Age +
m["b[2]"] * dat$OMElow +
m["b[3]"] * dat$Loud +
m["b[4]"] * dat$Noiseincoherent
phat <- 1 / (1 + exp(-eta))
obs_rate <- dat$Correct / dat$Trials
tab0.7 <- table(phat > 0.7, obs_rate > 0.7)
eta
# Posterior means for each coefficient
m <- mod_csim
eta <- m[1] +
m[2] * dat$Age +
m[3] * dat$OMElow +
m[4] * dat$Loud +
m[5] * dat$Noiseincoherent
phat <- 1 / (1 + exp(-eta))
obs_rate <- dat$Correct / dat$Trials
tab0.7 <- table(phat > 0.7, obs_rate > 0.7)
eta <- m[1] +
m[2] * dat$Age +
m[3] * dat$OMElow +
m[4] * dat$Loud +
m[5] * dat$Noiseincoherent
phat <- 1 / (1 + exp(-eta))
phat
m
eta <- m["b0"] +
m["b[1]"] * dat$Age +
m["b[2]"] * dat$OMElow +
m["b[3]"] * dat$Loud +
m["b[4]"] * dat$Noiseincoherent
phat <- 1 / (1 + exp(-eta))
eta <- m["b0"] +m["b[1]"] * dat$Age +m["b[2]"] * dat$OMElow +m["b[3]"] * dat$Loud + m["b[4]"] * dat$Noiseincoherent
eta <- m["b0"] +m["b[1]"] * dat$Age +m["b[2]"] * dat$OMElow +m["b[3]"] * dat$Loud + m["b[4]"] * dat$Noiseincoherent
View(dat)
# Posterior means for each coefficient
m <- mod_csim
eta <- m["b0"] +m["b[1]"] %*% dat$Age +m["b[2]"] %*% dat$OMElow +m["b[3]"] %*% dat$Loud + m["b[4]"] %*% dat$Noiseincoherent
phat <- 1 / (1 + exp(-eta))
obs_rate <- dat$Correct / dat$Trials
tab0.7 <- table(phat > 0.7, obs_rate > 0.7)
eta <- m["b0"] +m["b[1]"] %*% dat$Age +m["b[2]"] %*% dat$OMElow +m["b[3]"] %*% dat$Loud + m["b[4]"] %*% dat$Noiseincoherent
# Posterior means for each coefficient
m <- mod_csim
eta <- m["b0"] +
m["b[1]"] * dat$Age +
m["b[2]"] * dat$OMElow +
m["b[3]"] * dat$Loud +
m["b[4]"] * dat$Noiseincoherent
phat <- 1/(1+exp(-eta))
obs_rate <- dat$Correct / dat$Trials
tab0.7 <- table(phat > 0.7, obs_rate > 0.7)
names(m)
# Posterior means for each coefficient
m <- colMeans(do.call(rbind, mod_sim))
eta <- m["b0"] +
m["b[1]"] * dat$Age +
m["b[2]"] * dat$OMElow +
m["b[3]"] * dat$Loud +
m["b[4]"] * dat$Noiseincoherent
phat <- 1/(1+exp(-eta))
obs_rate <- dat$Correct / dat$Trials
tab0.7 <- table(phat > 0.7, obs_rate > 0.7)
names(m)
# Posterior means for each coefficient
m <- do.call(rbind, mod_sim)
eta <- m["b0"] +
m["b[1]"] * dat$Age +
m["b[2]"] * dat$OMElow +
m["b[3]"] * dat$Loud +
m["b[4]"] * dat$Noiseincoherent
phat <- 1/(1+exp(-eta))
obs_rate <- dat$Correct / dat$Trials
tab0.7 <- table(phat > 0.7, obs_rate > 0.7)
# Posterior means for each coefficient
m <- colMeans(as.matrix(mod_sim))   # preserves colnames
names(m)
eta <- m["b0"] +
m["b[1]"] * dat$Age +
m["b[2]"] * dat$OMElow +
m["b[3]"] * dat$Loud +
m["b[4]"] * dat$Noiseincoherent
# Posterior means for each coefficient
m <- colMeans(mod_csim)   # preserves colnames
names(m)
eta <- m["b0"] +
m["b[1]"] * dat$Age +
m["b[2]"] * dat$OMElow +
m["b[3]"] * dat$Loud +
m["b[4]"] * dat$Noiseincoherent
eta <- m["b0"]
eta <- m["b0"] + X[,c(1:4)] %*% pm_coef[1:4]
eta <- m["b0"] + X[,c(1:4)] %*% pm_coef[1:4]
eta <- m["b0"] + X[,c(1:4)] %*% m[1:4]
phat <- 1/(1+exp(-eta))
obs_rate <- dat$Correct / dat$Trials
tab0.7 <- table(phat > 0.7, obs_rate > 0.7)
tab0.7
accuracy <- sum(diag(tab0.7)) / sum(tab0.7)
round(accuracy, 2)
library("car")
data("Anscombe")
head(Anscombe)
?Anscombe
Xc = scale(Anscombe, center=TRUE, scale=TRUE)
str(Xc)
data_jags = as.list(data.frame(Xc))
ddexp
?ddexp
??ddexp
library("rjags")
mod_string <- "
model {
for (i in 1:N) {
education[i] ~ dnorm(mu[i], prec)
mu[i] <- b0 + b[1]*income[i] + b[2]*young[i] + b[3]*urban[i]
}
# Intercept: weakly-informative Normal
b0 ~ dnorm(0, 1.0E-6)
# Laplace(0, scale=1) for b[1:3] via Normal-Exponential mixture
for (j in 1:3) {
b[j] ~ dnorm(0, invtau[j])   # precision = invtau[j]
invtau[j] <- 1 / tau[j]
tau[j] ~ dexp(0.5)           # rate = 1/(2*scale^2) = 0.5 when scale=1
}
# Inverse-Gamma(0.5, 0.5) on sigma^2  <=>  Gamma(0.5,0.5) on precision
prec ~ dgamma(0.5, 0.5)
sig2 <- 1 / prec
sig  <- sqrt(sig2)
}
"
params = c("b0", "b", "sig")
mod_bayesian = jags.model(textConnection(mod_string), data=data_jags, inits=inits, n.chains=3)
update(mod_bayesian, 1000) # burn-in
samples = coda.samples(mod_bayesian, variable.names=params, n.iter=5000)
mod_bayesian = jags.model(textConnection(mod_string), data=data_jags, n.chains=3)
for (i in 1:n) {
mod_string <- "
mod_string <- "
model {
for (i in 1:n) {
education[i] ~ dnorm(mu[i], prec)
mu[i] <- b0 + b[1]*income[i] + b[2]*young[i] + b[3]*urban[i]
}
# Intercept: weakly-informative Normal
b0 ~ dnorm(0, 1.0E-6)
# Laplace(0, scale=1) for b[1:3] via Normal-Exponential mixture
for (j in 1:3) {
b[j] ~ dnorm(0, invtau[j])   # precision = invtau[j]
invtau[j] <- 1 / tau[j]
tau[j] ~ dexp(0.5)           # rate = 1/(2*scale^2) = 0.5 when scale=1
}
# Inverse-Gamma(0.5, 0.5) on sigma^2  <=>  Gamma(0.5,0.5) on precision
prec ~ dgamma(0.5, 0.5)
sig2 <- 1 / prec
sig  <- sqrt(sig2)
}
"
mod_string <- " model {
mod_string <- " model {
} "
mod_string = " model {
library("rjags")
mod_string <- " model {
for (i in 1:n) {
education[i] ~ dnorm(mu[i], prec)
mu[i] <- b0 + b[1]*income[i] + b[2]*young[i] + b[3]*urban[i]
}
# Intercept: weakly-informative Normal
b0 ~ dnorm(0, 1.0E-6)
# Laplace(0, scale=1) for b[1:3] via Normal-Exponential mixture
for (j in 1:3) {
b[j] ~ dnorm(0, invtau[j])   # precision = invtau[j]
invtau[j] <- 1 / tau[j]
tau[j] ~ dexp(0.5)           # rate = 1/(2*scale^2) = 0.5 when scale=1
}
# Inverse-Gamma(0.5, 0.5) on sigma^2  <=>  Gamma(0.5,0.5) on precision
prec ~ dgamma(0.5, 0.5)
sig2 <- 1 / prec
sig  <- sqrt(sig2)
} "
params = c("b0", "b", "sig")
mod_bayesian = jags.model(textConnection(mod_string), data=data_jags, n.chains=3)
update(mod_bayesian, 1000) # burn-in
samples = coda.samples(mod_bayesian, variable.names=params, n.iter=5000)
mod_bayesian = jags.model(textConnection(mod_string), data=data_jags, n.chains=3)
str(Xc)
Xc
library("rjags")
mod_string <- " model {
for (i in 1:length(education)) {
education[i] ~ dnorm(mu[i], prec)
mu[i] <- b0 + b[1]*income[i] + b[2]*young[i] + b[3]*urban[i]
}
# Intercept: weakly-informative Normal
b0 ~ dnorm(0, 1.0E-6)
# Laplace(0, scale=1) for b[1:3] via Normal-Exponential mixture
for (j in 1:3) {
b[j] ~ dnorm(0, invtau[j])   # precision = invtau[j]
invtau[j] <- 1 / tau[j]
tau[j] ~ dexp(0.5)           # rate = 1/(2*scale^2) = 0.5 when scale=1
}
# Inverse-Gamma(0.5, 0.5) on sigma^2  <=>  Gamma(0.5,0.5) on precision
prec ~ dgamma(0.5, 0.5)
sig2 <- 1 / prec
sig  <- sqrt(sig2)
} "
params = c("b0", "b", "sig")
mod_bayesian = jags.model(textConnection(mod_string), data=data_jags, n.chains=3)
update(mod_bayesian, 1000) # burn-in
samples = coda.samples(mod_bayesian, variable.names=params, n.iter=5000)
summary(samples)
knitr::opts_chunk$set(warning = FALSE, message = FALSE)
rm(list = ls())
options(warn = -1)
library(tidyverse)
library(lme4)
library(lmerTest)
library(ggplot2)
library(aida)
library(BayesFactor)
library(pwr)
library(brms)
library(emmeans)
library(effsize)
library(HDInterval)
theme_set(theme_aida())
##################################################
## CSP-colors
##################################################
CSP_colors = c(
"#7581B3", "#99C2C2", "#C65353", "#E2BA78", "#5C7457", "#575463",
"#B0B7D4", "#66A3A3", "#DB9494", "#D49735", "#9BB096", "#D4D3D9",
"#414C76", "#993333"
)
# setting theme colors globally
scale_colour_discrete <- function(...) {
scale_colour_manual(..., values = CSP_colors)
}
scale_fill_discrete <- function(...) {
scale_fill_manual(..., values = CSP_colors)
}
data <- read.csv("../../data/pilot-2b/results.csv")
#data$id <- as.factor(1:nrow(data))
data$F1_NP <- as.factor(data$F1_NP)
data$F2_visual <- as.factor(data$F2_visual)
data %>% mutate(alternative = ifelse(itemNr < 73, "yes", "no") ) -> data
practice_itemNr_list <- c(801,802,803)
filler_itemNr_list <- c(901:924)
data_filler <- data %>% select(submission_id,
acceptability,
List, itemNr,
F1_NP,
F2_visual)%>%
filter(itemNr %in% filler_itemNr_list)
data <- data %>% select(submission_id,
acceptability,
List,
itemNr,
alternative,
F1_NP,
F2_visual) %>%
filter(!itemNr %in% practice_itemNr_list & !itemNr %in% filler_itemNr_list)
data %>% group_by(List) %>% summarise(n = n()/24)
ggplot(data, aes(x = acceptability)) +
geom_histogram(binwidth = 5, fill = CSP_colors[1]) +
facet_wrap(alternative ~ F2_visual, scales = "free_y") +
labs(title = "Distribution of Acceptability Ratings",
x = "Acceptability",
y = "Frequency")
ggplot(data, aes(x = acceptability)) +
geom_density(fill = CSP_colors[1]) +
facet_wrap(~ F2_visual, scales = "free_y") +
labs(title = "Distribution of updated probs",
x = "Acceptability",
y = "Density")
library(ggpubr)
# Ensure factor order
data$F2_visual <- factor(data$F2_visual,
levels = c("notGrouped", "randomGrouped", "colorGrouped"))
data$condition <- paste(data$alternative, data$F2_visual, sep = "_")
data$condition <- factor(data$condition,
levels = c("no_notGrouped", "no_randomGrouped", "no_colorGrouped",
"yes_notGrouped", "yes_randomGrouped", "yes_colorGrouped"))
sig_df <- data.frame(
group1 = c(
"no_randomGrouped",  # within 'no'
"no_notGrouped",     # across
"yes_randomGrouped"  # within 'yes'
),
group2 = c(
"no_colorGrouped",        # within 'no'
"yes_notGrouped",         # across
"yes_colorGrouped"        # within 'yes'
),
y.position = c(110, 120, 110),
significance = c("***", "***", "***")
)
custom_labels <- c(
"no_notGrouped" = "notGrouped",
"no_randomGrouped" = "randomGrouped",
"no_colorGrouped" = "colorGrouped",
"yes_notGrouped" = "notGrouped",
"yes_randomGrouped" = "randomGrouped",
"yes_colorGrouped" = "colorGrouped"
)
# Create plot
p1 <- ggplot(data, aes(x = condition, y = acceptability)) +
geom_boxplot(aes(fill = F2_visual)) +
stat_pvalue_manual(sig_df, label = "significance", tip.length = 0.01) +
#facet_wrap(~alternative) +  # ðŸ‘ˆ facet by "alternative"
labs(
x = "Visual Context",
y = "Acceptability"
) +
theme(axis.text.x = element_text(angle = 30, hjust = 1)) +
theme(legend.position = "bottom",
legend.title = element_blank()) +
annotate("text", x = 2, y = 135, label = "Comparison: no", size = 4, fontface = "bold") +
annotate("text", x = 5, y = 135, label = "Comparison: yes", size = 4, fontface = "bold") +
scale_x_discrete(labels = custom_labels)
# Save to file
ggsave("pilot2b_boxplot.png", p1, width = 7, height = 5, dpi = 300)
# Show plot
p1
# plot mean and CIs for better visualization
data %>% group_by(F2_visual, alternative) %>%
summarise(mean = mean(acceptability, na.rm = TRUE),
sd = sd(acceptability, na.rm = TRUE),
N = n()) %>%
ggplot(aes(x = F2_visual, y = mean, color = alternative)) +
geom_point() +
geom_errorbar(aes(ymin = mean - sd/sqrt(N), ymax = mean + sd/sqrt(N)), width = 0.2) +
labs(
x = "Visual Context",
y = "Mean Acceptability")
data %>%
group_by(F2_visual) %>%
summarise(
Mean = mean(acceptability, na.rm = TRUE),
SD = sd(acceptability, na.rm = TRUE),
N = n()
)
false_control_itemNr_list <- seq(901, 924, 2)
data_filler %>% group_by(itemNr) %>% summarise(mean(acceptability))
# Make a plot with mean and CIs for better visualization
data_filler %>% filter(itemNr %in% false_control_itemNr_list) %>% ggplot(aes(x = F1_NP, y = acceptability)) +
stat_summary(fun.data = mean_cl_normal) +
geom_hline(yintercept = 50, linetype = "dashed") +
labs(
title = "Acceptability Ratings for False Controls \n (902, 904, 906)",
x = "Item Number",
y = "Acceptability"
)
# all data
shapiro.test(data$acceptability) #Not passed.
data$F1_NP <- droplevels(data$F1_NP)
lmer_model_full <- lmer(acceptability ~ F2_visual * alternative + (1|submission_id) + (1|itemNr), data = data)
lmer_model_reduced <- lmer(acceptability ~ F2_visual + alternative + (1|submission_id) + (1|itemNr), data = data)
anova(lmer_model_reduced, lmer_model_full)
summary(lmer_model_full)
emmeans(lmer_model_full, pairwise ~ alternative * F2_visual, adjust = "bonferroni")
step(lmer_model_full, direction = "backward")
brm_full_model <- brm(acceptability ~ F1_NPforms * F2_matchness + (1|submission_id) + (1|itemNr), data = data, sample_prior = "yes", prior = c(brms::prior("normal(0, 100)")), save_pars = save_pars(all = TRUE))
knitr::opts_chunk$set(warning = FALSE, message = FALSE)
rm(list = ls())
options(warn = -1)
library(tidyverse)
library(lme4)
library(lmerTest)
library(ggplot2)
library(aida)
library(BayesFactor)
library(pwr)
library(brms)
library(emmeans)
library(effsize)
library(HDInterval)
theme_set(theme_aida())
##################################################
## CSP-colors
##################################################
CSP_colors = c(
"#7581B3", "#99C2C2", "#C65353", "#E2BA78", "#5C7457", "#575463",
"#B0B7D4", "#66A3A3", "#DB9494", "#D49735", "#9BB096", "#D4D3D9",
"#414C76", "#993333"
)
# setting theme colors globally
scale_colour_discrete <- function(...) {
scale_colour_manual(..., values = CSP_colors)
}
scale_fill_discrete <- function(...) {
scale_fill_manual(..., values = CSP_colors)
}
data_batch1 <- read.csv("../data/pilot-2a/results_batch1.csv")
data_batch2 <- read.csv("../data/pilot-2a/results_batch2.csv")
data <- rbind(data_batch1, data_batch2)
#data$id <- as.factor(1:nrow(data))
data$F1_NP <- as.factor(data$F1_NP)
data$F2_visual <- as.factor(data$F2_visual)
practice_itemNr_list <- c(801,802,803)
filler_itemNr_list <- c(901:924)
data_filler <- data %>% select(submission_id,,
acceptability,
List, itemNr,
F1_NPforms,
F2_matchness)%>%
filter(itemNr %in% filler_itemNr_list)
data_def <- data %>% select(submission_id,
acceptability,
List,
itemNr,
F1_NP,
F2_visual) %>%
filter(!itemNr %in% practice_itemNr_list & !itemNr %in% filler_itemNr_list)
data_batch1 <- read.csv("../data/pilot-2a/results_batch1.csv")
data_batch2 <- read.csv("../data/pilot-2a/results_batch2.csv")
data <- rbind(data_batch1, data_batch2)
#data$id <- as.factor(1:nrow(data))
data$F1_NP <- as.factor(data$F1_NP)
data$F2_visual <- as.factor(data$F2_visual)
practice_itemNr_list <- c(801,802,803)
filler_itemNr_list <- c(901:924)
data_filler <- data %>% select(submission_id,,
acceptability,
List, itemNr,
F1_NPforms,
F2_matchness)%>%
filter(itemNr %in% filler_itemNr_list)
data_def <- data %>% select(submission_id,
acceptability,
List,
itemNr,
F1_NP,
F2_visual) %>%
filter(!itemNr %in% practice_itemNr_list & !itemNr %in% filler_itemNr_list)
View(data)
practice_itemNr_list <- c(801,802,803)
filler_itemNr_list <- c(901:924)
data_filler <- data %>% select(submission_id,,
acceptability,
List, itemNr,
F1_NP,
F2_viusal)%>%
filter(itemNr %in% filler_itemNr_list)
data_def <- data %>% select(submission_id,
acceptability,
List,
itemNr,
F1_NP,
F2_visual) %>%
filter(!itemNr %in% practice_itemNr_list & !itemNr %in% filler_itemNr_list)
